# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000, 30) строк, столбцов
- Целевая переменная: `target` (класс 0: 8119 примеров, 67.66%; класс 1: 3881 примеров, 32.34%)
- Признаки: 28 признаков - числовые признаки (num01-num24), категориальные признаки (cat_contract, cat_region, cat_payment), числовой признак tenure_months. Все признаки числового типа (float64 или int64), пропущенных значений нет.

## 2. Protocol

- Разбиение: train/test (80/20, `random_state=42`)
- Подбор: CV на train (5 фолдов, оптимизация ROC-AUC)
- Метрики: accuracy, F1, ROC-AUC (ROC-AUC хорошо подходит для бинарной классификации, F1 учитывает дисбаланс классов, accuracy дает общее представление о качестве)

## 3. Models

Сравнивались следующие модели с подбором гиперпараметров через GridSearchCV (5-фолдовая кросс-валидация на train, оптимизация ROC-AUC):

Минимум:

- DummyClassifier (baseline) - стратегия `most_frequent`, без подбора параметров. Используется как нижняя планка качества.
- LogisticRegression (baseline из S05) - с Pipeline(StandardScaler + LogisticRegression), подбор C: [0.1, 1.0, 10.0, 100.0]. Лучшие параметры: `C=1.0`, CV ROC-AUC: 0.8822.
- DecisionTreeClassifier - контроль сложности через подбор гиперпараметров:
  - max_depth: [None, 5, 10, 15]
  - min_samples_leaf: [1, 5, 10, 20]
  - ccp_alpha: [0.0, 0.001, 0.01]
  Лучшие параметры: `max_depth=None, min_samples_leaf=20, ccp_alpha=0.0`, CV ROC-AUC: 0.9183.
- RandomForestClassifier - ансамбль деревьев с bagging:
  - max_depth: [None, 10, 20]
  - min_samples_leaf: [1, 5, 10]
  - max_features: ['sqrt', 0.5]
  - n_estimators=100 (фиксировано)
  Лучшие параметры: `max_depth=None, max_features='sqrt', min_samples_leaf=1`, CV ROC-AUC: 0.9691.
- HistGradientBoostingClassifier - градиентный бустинг:
  - learning_rate: [0.05, 0.1, 0.2]
  - max_depth: [3, 5, None]
  - max_leaf_nodes: [15, 31, 63]
  - early_stopping=True (включено для предотвращения переобучения)
  Лучшие параметры: `learning_rate=0.2, max_depth=None, max_leaf_nodes=63`, CV ROC-AUC: 0.9734.

Опционально:

- StackingClassifier (не реализован)

## 4. Results

Таблица финальных метрик на test по всем моделям:

| Модель | Accuracy | F1 | ROC-AUC |
|--------|----------|----|-----------| 
| HistGradientBoosting | 0.9296 | 0.8876 | 0.9713 |
| RandomForest | 0.9258 | 0.8792 | 0.9666 |
| DecisionTree | 0.8692 | 0.7942 | 0.9098 |
| LogReg(scaled) | 0.8275 | 0.7076 | 0.8747 |
| Dummy(most_frequent) | 0.6767 | 0.0000 | 0.5000 |

- Победитель: HistGradientBoosting по ROC-AUC (0.9713). Эта модель показала наилучшие результаты по всем метрикам. Градиентный бустинг с оптимальными гиперпараметрами (learning_rate=0.2, max_depth=None, max_leaf_nodes=63) достиг отличного баланса между сложностью модели и обобщающей способностью, значительно превзойдя как baseline модели, так и другие ансамблевые подходы. ROC-AUC 0.9713 указывает на очень хорошее качество ранжирования примеров по вероятности принадлежности к положительному классу.

## 5. Analysis

- Устойчивость: при изменении `random_state` небольшой разброс метрик для всех моделей. Для ансамблевых моделей (RandomForest, HistGradientBoosting) вариативность ниже благодаря усреднению множества слабых классификаторов. Для DecisionTree разброс выше из-за чувствительности одиночного дерева к начальным условиям.

- Ошибки: Confusion Matrix для лучшей модели (HistGradientBoosting):

```
            Предсказано
           0      1
Истина 0  1564   60
       1  109    667
```
- True Negatives (TN): 1564 - правильно классифицированные отрицательные примеры
- False Positives (FP): 60 - отрицательные примеры, ошибочно классифицированные как положительные
- False Negatives (FN): 109 - положительные примеры, ошибочно классифицированные как отрицательные
- True Positives (TP): 667 - правильно классифицированные положительные примеры

Precision (для класса 1): 667/(667+60) = 0.917 - модель показывает высокую точность при предсказании положительного класса. Recall (для класса 1): 667/(667+109) = 0.860 - модель находит 86% всех положительных примеров. Баланс между precision и recall хороший, что важно для задачи с умеренным дисбалансом классов.

- Интерпретация: permutation importance (top-15 признаков):

Топ-10 наиболее важных признаков:
1. num19: 0.0694
2. num18: 0.0658
3. num07: 0.0361
4. num04: 0.0203
5. num01: 0.0147
6. num24: 0.0141
7. num14: 0.0127
8. num20: 0.0111
9. num22: 0.0089
10. num16: 0.0062

- Признаки num19 и num18 имеют значительно более высокую важность (примерно 0.07) по сравнению с остальными, что указывает на их ключевую роль в предсказаниях модели.
- Следующие по важности признаки (num07, num04, num01) имеют умеренную важность (0.01-0.04), остальные признаки вносят меньший вклад.
- Категориальные признаки (cat_contract, cat_region, cat_payment) и tenure_months не вошли в топ-15, что может указывать на то, что числовые признаки num19 и num18 содержат основную информацию для классификации.
- Наблюдается четкая иерархия важности признаков, что характерно для хорошо работающих моделей на табличных данных.

## 6. Conclusion

1. **Деревья решений** склонны к переобучению без контроля сложности. В эксперименте DecisionTree с max_depth=None показал худшие результаты среди моделей недели 6, но применение min_samples_leaf=20 помогло частично контролировать переобучение, достигнув ROC-AUC 0.9098.

2. **Ансамбли эффективны**: RandomForest и HistGradientBoosting значительно превзошли одиночное дерево (ROC-AUC 0.9666 и 0.9713 против 0.9098). Это подтверждает, что объединение множества моделей позволяет снизить дисперсию предсказаний и улучшить обобщающую способность.

3. **Градиентный бустинг** показал наилучшие результаты на данном датасете. HistGradientBoosting с оптимальными гиперпараметрами (learning_rate=0.2, max_leaf_nodes=63) достиг ROC-AUC 0.9713, что выше чем у RandomForest, демонстрируя эффективность последовательного обучения слабых классификаторов.

4. **Честный ML-протокол критичен**: использование CV на train для подбора гиперпараметров и финальной оценки на test один раз позволило корректно сравнить модели без переобучения на тестовой выборке. Разница между CV-оценками и тестовыми метриками была небольшой (<3%), что указывает на хорошую согласованность результатов.

